{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARK: note_rns - 192.168.18.118\n",
      "MINIO: 62.72.11.215\n"
     ]
    }
   ],
   "source": [
    "import socket, os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark_hostname = socket.gethostname()\n",
    "spark_ip_address = socket.gethostbyname(spark_hostname)\n",
    "minio_ip_address = \"62.72.11.215\"\n",
    "\n",
    "## DEFINIDO O MESMO IP POIS OS SERVIÇOS VÃO EXECUTAR NO MESMO SERVIDOR\n",
    "print(f\"SPARK: {spark_hostname} - {spark_ip_address}\")\n",
    "print(f\"MINIO: {minio_ip_address}\")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.1.1,com.amazonaws:aws-java-sdk-bundle:1.12.469,org.apache.hadoop:hadoop-aws:3.3.4\")\n",
    "\n",
    "    # CONFIGURA EXTENSÃO DO DELTA\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "    # LIMITA USO DE CORE E MEMORIA POR EXECUTOR\n",
    "    .config(\"spark.cores.max\", \"1\")\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "\n",
    "    # CONFIGURAÇÃO PARA COMUNICAR COM PROTOCOLO S3\n",
    "    .config(\"spark.driver.bindAddress\", f\"{spark_hostname}\")\n",
    "    .config(\"spark.driver.host\", f\"{spark_ip_address}\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minio\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minio123\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", f\"http://{minio_ip_address}:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "\n",
    "    .config(\"spark.network.timeout\", \"480s\")\n",
    "    .config(\"spark.scheduler.barrier.maxConcurrentTasksCheck.maxFailures\", \"5\")\n",
    "    .config(\"spark.rdd.compress\", \"true\")\n",
    "    .config(\"spark.shuffle.compress\", \"true\")\n",
    "    .config(\"spark.shuffle.spill.compress\", \"true\")\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC -XX:+G1SummarizeConcMark\")\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-XX:+UseG1GC -XX:+G1SummarizeConcMark\")\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"512m\")\n",
    "\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
    "\n",
    "    # CRIA SESSÃO DO SPARK\n",
    "    .master(f\"spark://{spark_ip_address}:7077\")\n",
    "    .appName(\"rascunho\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# hadoop_base_path = os.getenv(\"HADOOP_HOME\").replace(\"\\\\\", \"/\")\n",
    "# hadoop_config = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "# hadoop_config.set(\"driver.extraClassPath\", f\"{hadoop_base_path}/lib/native/hadoop-aws-3.3.1.jar:{hadoop_base_path}/lib/native/aws-java-sdk-1.12.153\")\n",
    "\n",
    "# for key, value in [(k.replace(\"spark.hadoop.\", \"\"), v) for k, v in spark.sparkContext.getConf().getAll() if k.find(\"hadoop\") != -1]:\n",
    "#     hadoop_config.set(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- codigo_uf: long (nullable = true)\n",
      " |-- uf: string (nullable = true)\n",
      " |-- nome: string (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      " |-- regiao: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estados = spark.read.csv(\n",
    "    path=\"s3a://datalake/raw/municipios_brasileiros/estados.csv.gz\", \n",
    "    schema=\"codigo_uf LONG, uf STRING, nome STRING, latitude FLOAT, longitude FLOAT, regiao STRING\",\n",
    "    header=True\n",
    ")\n",
    "\n",
    "estados.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+-------------------+--------+---------+--------+\n",
      "|codigo_uf|uf |nome               |latitude|longitude|regiao  |\n",
      "+---------+---+-------------------+--------+---------+--------+\n",
      "|11       |RO |Rondônia           |-10.83  |-63.34   |Norte   |\n",
      "|12       |AC |Acre               |-8.77   |-70.55   |Norte   |\n",
      "|13       |AM |Amazonas           |-3.47   |-65.1    |Norte   |\n",
      "|14       |RR |Roraima            |1.99    |-61.33   |Norte   |\n",
      "|15       |PA |Pará               |-3.79   |-52.48   |Norte   |\n",
      "|16       |AP |Amapá              |1.41    |-51.77   |Norte   |\n",
      "|17       |TO |Tocantins          |-9.46   |-48.26   |Norte   |\n",
      "|21       |MA |Maranhão           |-5.42   |-45.44   |Nordeste|\n",
      "|22       |PI |Piauí              |-6.6    |-42.28   |Nordeste|\n",
      "|23       |CE |Ceará              |-5.2    |-39.53   |Nordeste|\n",
      "|24       |RN |Rio Grande do Norte|-5.81   |-36.59   |Nordeste|\n",
      "|25       |PB |Paraíba            |-7.28   |-36.72   |Nordeste|\n",
      "|26       |PE |Pernambuco         |-8.38   |-37.86   |Nordeste|\n",
      "|27       |AL |Alagoas            |-9.62   |-36.82   |Nordeste|\n",
      "|28       |SE |Sergipe            |-10.57  |-37.45   |Nordeste|\n",
      "|29       |BA |Bahia              |-13.29  |-41.71   |Nordeste|\n",
      "|31       |MG |Minas Gerais       |-18.1   |-44.38   |Sudeste |\n",
      "|32       |ES |Espírito Santo     |-19.19  |-40.34   |Sudeste |\n",
      "|33       |RJ |Rio de Janeiro     |-22.25  |-42.66   |Sudeste |\n",
      "|35       |SP |São Paulo          |-22.19  |-48.79   |Sudeste |\n",
      "+---------+---+-------------------+--------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estados.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- codigo_ibge: long (nullable = true)\n",
      " |-- nome: string (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      " |-- capital: integer (nullable = true)\n",
      " |-- codigo_uf: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "municipios = spark.read.csv(\n",
    "    path=\"s3a://datalake/raw/municipios_brasileiros/municipios.csv.gz\", \n",
    "    schema=\"codigo_ibge LONG, nome STRING, latitude FLOAT, longitude FLOAT, capital INT, codigo_uf LONG\",\n",
    "    # schema=\"codigo_ibge LONG, nome STRING, latitude FLOAT, longitude FLOAT, capital INT, codigo_uf LONG, siafi_id LONG, ddd LONG, fuso_horario STRING\",\n",
    "    header=True\n",
    ")\n",
    "\n",
    "municipios.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+--------+---------+-------+---------+\n",
      "|codigo_ibge|nome               |latitude|longitude|capital|codigo_uf|\n",
      "+-----------+-------------------+--------+---------+-------+---------+\n",
      "|5200050    |Abadia de Goiás    |-16.7573|-49.4412 |0      |52       |\n",
      "|3100104    |Abadia dos Dourados|-18.4831|-47.3916 |0      |31       |\n",
      "|5200100    |Abadiânia          |-16.197 |-48.7057 |0      |52       |\n",
      "|3100203    |Abaeté             |-19.1551|-45.4444 |0      |31       |\n",
      "|1500107    |Abaetetuba         |-1.72183|-48.8788 |0      |15       |\n",
      "|2300101    |Abaiara            |-7.34588|-39.0416 |0      |23       |\n",
      "|2900108    |Abaíra             |-13.2488|-41.6619 |0      |29       |\n",
      "|2900207    |Abaré              |-8.72073|-39.1162 |0      |29       |\n",
      "|4100103    |Abatiá             |-23.3049|-50.3133 |0      |41       |\n",
      "|4200051    |Abdon Batista      |-27.6126|-51.0233 |0      |42       |\n",
      "|1500131    |Abel Figueiredo    |-4.95333|-48.3933 |0      |15       |\n",
      "|4200101    |Abelardo Luz       |-26.5716|-52.3229 |0      |42       |\n",
      "|3100302    |Abre Campo         |-20.2996|-42.4743 |0      |31       |\n",
      "|2600054    |Abreu e Lima       |-7.90072|-34.8984 |0      |26       |\n",
      "|1700251    |Abreulândia        |-9.62101|-49.1518 |0      |17       |\n",
      "|3100401    |Acaiaca            |-20.359 |-43.1439 |0      |31       |\n",
      "|2100055    |Açailândia         |-4.94714|-47.5004 |0      |21       |\n",
      "|2900306    |Acajutiba          |-11.6575|-38.0197 |0      |29       |\n",
      "|1500206    |Acará              |-1.95383|-48.1985 |0      |15       |\n",
      "|2300150    |Acarape            |-4.22083|-38.7055 |0      |23       |\n",
      "+-----------+-------------------+--------+---------+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "municipios.show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALVE REFINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "refined = (\n",
    "    spark.read.load(\n",
    "        path=\"s3a://datalake/trusted/municipios_brasileiros\",\n",
    "        format=\"delta\",\n",
    "    )\n",
    "    .selectExpr([\n",
    "        \"codigo_ibge\",\n",
    "        \"nome\",\n",
    "        \"e_capital\",\n",
    "        \"uf\",\n",
    "        \"nome_estado\",\n",
    "        \"regiao\",\n",
    "        \"current_timestamp() AS gerado_em\"\n",
    "    ])\n",
    ")\n",
    "\n",
    "(\n",
    "    refined.write\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(\"s3a://datalake/refined/municipios_brasileiros\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALVE TRUSTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trusted = (\n",
    "    municipios.alias(\"m\").join(\n",
    "        other=estados.alias(\"e\"),\n",
    "        on=(municipios.codigo_uf == estados.codigo_uf),\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .selectExpr([\n",
    "        \"m.codigo_ibge\",\n",
    "        \"m.nome\",\n",
    "        \"m.latitude\",\n",
    "        \"m.longitude\",\n",
    "        \"(m.capital == 1) AS e_capital\",\n",
    "        \"e.uf\",\n",
    "        \"e.nome AS nome_estado\",\n",
    "        \"e.regiao\",\n",
    "        \"current_timestamp() AS gerado_em\",\n",
    "    ])\n",
    "    .distinct()\n",
    ")\n",
    "\n",
    "# trusted.show(truncate=False)\n",
    "\n",
    "trusted = (\n",
    "    trusted\n",
    "    .withMetadata(\"codigo_ibge\", { \"tipo\": \"NUMERICO\", \"descricao\": \"Código composto de 7 dígitos, sendo os dois primeiros referentes ao código da Unidade da Federação\" })\n",
    "    .withMetadata(\"nome\", { \"tipo\": \"TEXTO\", \"descricao\": \"Nome do município\" })\n",
    "    .withMetadata(\"latitude\", { \"tipo\": \"NUMERICO\", \"descricao\": \"Latitude do município\" })\n",
    "    .withMetadata(\"longitude\", { \"tipo\": \"NUMERICO\", \"descricao\": \"Longitude do município\" })\n",
    "    .withMetadata(\"e_capital\", { \"tipo\": \"BOOLEANO\", \"descricao\": \"Identifica se o município é ou não capital do estado\" })\n",
    "    .withMetadata(\"uf\", { \"tipo\": \"TEXTO\", \"descricao\": \"Unidade Federativa que identifica o estado\" })\n",
    "    .withMetadata(\"nome_estado\", { \"tipo\": \"TEXTO\", \"descricao\": \"Nome do estado\" })\n",
    "    .withMetadata(\"regiao\", { \"tipo\": \"TEXTO\", \"descricao\": \"Agrupamento das UFs\" })\n",
    "    .withMetadata(\"gerado_em\", { \"tipo\": \"DATA E HORA\", \"descricao\": \"Identifica a data e hora que o registro foi gerado pela orquestração\" })\n",
    ")\n",
    "\n",
    "(\n",
    "    trusted.write\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(\"s3a://datalake/trusted/municipios_brasileiros\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
