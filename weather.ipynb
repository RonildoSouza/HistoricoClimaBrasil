{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARK: note_rns - 192.168.18.118\n",
      "MINIO: 62.72.11.215\n"
     ]
    }
   ],
   "source": [
    "import socket, os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark_hostname = socket.gethostname()\n",
    "spark_ip_address = socket.gethostbyname(spark_hostname)\n",
    "minio_ip_address = \"62.72.11.215\"\n",
    "\n",
    "## DEFINIDO O MESMO IP POIS OS SERVIÇOS VÃO EXECUTAR NO MESMO SERVIDOR\n",
    "print(f\"SPARK: {spark_hostname} - {spark_ip_address}\")\n",
    "print(f\"MINIO: {minio_ip_address}\")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.1.1,com.amazonaws:aws-java-sdk-bundle:1.12.469,org.apache.hadoop:hadoop-aws:3.3.4\")\n",
    "\n",
    "    # CONFIGURA EXTENSÃO DO DELTA\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "    # LIMITA USO DE CORE E MEMORIA POR EXECUTOR\n",
    "    .config(\"spark.cores.max\", \"2\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "\n",
    "    # CONFIGURAÇÃO PARA COMUNICAR COM PROTOCOLO S3\n",
    "    .config(\"spark.driver.bindAddress\", f\"{spark_hostname}\")\n",
    "    .config(\"spark.driver.host\", f\"{spark_ip_address}\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minio\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minio123\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", f\"http://{minio_ip_address}:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "\n",
    "    # CRIA SESSÃO DO SPARK\n",
    "    .master(f\"spark://{spark_ip_address}:7077\")\n",
    "    .appName(\"rascunho\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# hadoop_base_path = os.getenv(\"HADOOP_HOME\").replace(\"\\\\\", \"/\")\n",
    "# hadoop_config = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "# hadoop_config.set(\"driver.extraClassPath\", f\"{hadoop_base_path}/lib/native/hadoop-aws-3.3.1.jar:{hadoop_base_path}/lib/native/aws-java-sdk-1.12.153\")\n",
    "\n",
    "# for key, value in [(k.replace(\"spark.hadoop.\", \"\"), v) for k, v in spark.sparkContext.getConf().getAll() if k.find(\"hadoop\") != -1]:\n",
    "#     hadoop_config.set(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALVE RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipios = spark.read.load(\n",
    "    path=\"s3a://datalake/trusted/municipios_brasileiros\", \n",
    "    format=\"delta\"\n",
    ")\n",
    "\n",
    "municipios.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import json\n",
    "# import boto3 \n",
    "import requests\n",
    "from uuid import uuid4\n",
    "from datetime import datetime\n",
    "\n",
    "# s3 = boto3.resource(\n",
    "#     's3', \n",
    "#     aws_access_key_id=\"minio\",\n",
    "#     aws_secret_access_key=\"minio123\",\n",
    "#     endpoint_url=f\"http://{minio_ip_address}:9000\", \n",
    "#     use_ssl=False\n",
    "# )\n",
    "\n",
    "years = [\n",
    "    2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
    "]\n",
    "\n",
    "for year in years:\n",
    "    base_path = f'C:/Users/Ronildo/Downloads/clima_municipios_brasileiros/{year}'\n",
    "\n",
    "    if not os.path.exists(base_path):\n",
    "        os.makedirs(base_path)\n",
    "\n",
    "    # for row in municipios.filter(\"NOT e_capital\").orderBy(\"regiao\", \"codigo_ibge\").collect():\n",
    "    # for row in municipios.filter(~municipios.codigo_ibge.isin(collection)).orderBy(\"regiao\", \"codigo_ibge\").collect():\n",
    "    for row in municipios.orderBy(\"regiao\", \"codigo_ibge\").collect():\n",
    "        resp = requests.get(f\"https://archive-api.open-meteo.com/v1/era5?latitude={row.latitude}&longitude={row.longitude}&start_date={year}-01-01&end_date={year}-12-31&hourly=temperature_2m,relativehumidity_2m,windspeed_10m&timezone=America/Sao_Paulo\")\n",
    "        resp.raise_for_status()\n",
    "\n",
    "        # (\n",
    "        #     s3.Object('datalake', f'raw/clima_municipios_brasileiros/2000_2022/{row.regiao}/{datetime.today().strftime(\"%Y%m%d%H%M%S\")}_{uuid4()}.json')\n",
    "        #     .put(\n",
    "        #         Body=(bytes(json.dumps({ \"responses\": resp.json() }).encode('UTF-8')))\n",
    "        #     )\n",
    "        # )\n",
    "\n",
    "        with gzip.open(f'{base_path}/{row.regiao}/{row.codigo_ibge}_{datetime.today().strftime(\"%Y%m%d%H%M%S\")}_{uuid4()}.json.gz', 'wb') as f_out:\n",
    "            encoded = json.dumps({ \"codigo_ibge\": row.codigo_ibge, \"payload\": resp.json() }).encode('utf-8')\n",
    "            # compressed = gzip.compress(encoded)\n",
    "            f_out.write(encoded)\n",
    "\n",
    "    print(f\"{year} salvo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gzip\n",
    "# import glob\n",
    "\n",
    "# files = glob.glob(\"C:/Users/Ronildo/Downloads/clima_municipios_brasileiros/2000_2022/Nordeste/*\")\n",
    "\n",
    "# for file in files:\n",
    "#     with open(file, 'rb') as f_in, \\\n",
    "#         gzip.open(f'{file}.gz', 'wb') as f_out:\n",
    "#         f_out.writelines(f_in)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALVE REFINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- codigo_ibge: long (nullable = true)\n",
      " |-- payload: struct (nullable = true)\n",
      " |    |-- elevation: double (nullable = true)\n",
      " |    |-- generationtime_ms: double (nullable = true)\n",
      " |    |-- hourly: struct (nullable = true)\n",
      " |    |    |-- relativehumidity_2m: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- temperature_2m: array (nullable = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- time: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- windspeed_10m: array (nullable = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |    |-- hourly_units: struct (nullable = true)\n",
      " |    |    |-- relativehumidity_2m: string (nullable = true)\n",
      " |    |    |-- temperature_2m: string (nullable = true)\n",
      " |    |    |-- time: string (nullable = true)\n",
      " |    |    |-- windspeed_10m: string (nullable = true)\n",
      " |    |-- latitude: double (nullable = true)\n",
      " |    |-- longitude: double (nullable = true)\n",
      " |    |-- timezone: string (nullable = true)\n",
      " |    |-- timezone_abbreviation: string (nullable = true)\n",
      " |    |-- utc_offset_seconds: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clima_municipios = spark.read.json(\n",
    "    path=\"s3a://datalake/raw/clima_municipios_brasileiros/2000_2022\",\n",
    "    # path=\"s3a://datalake/raw/clima_municipios_brasileiros/2000_2022/Centro-Oeste\",\n",
    "    # path=\"s3a://datalake/raw/clima_municipios_brasileiros/2000_2022/Nordeste\",\n",
    "    # path=\"s3a://datalake/raw/clima_municipios_brasileiros/2000_2022/Norte\",\n",
    "    # path=\"s3a://datalake/raw/clima_municipios_brasileiros/2000_2022/Sudeste\",\n",
    "    # path=\"s3a://datalake/raw/clima_municipios_brasileiros/2000_2022/Sul\",\n",
    "    # path=\"s3a://datalake/raw/clima_municipios_brasileiros/2022\",\n",
    "    recursiveFileLookup=True\n",
    ")\n",
    "\n",
    "clima_municipios.createOrReplaceTempView(\"clima_municipios\")\n",
    "clima_municipios.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refined - TEMPORALIDADE\n",
    "refined = spark.sql(\"\"\"\n",
    "    WITH _time AS (\n",
    "        SELECT DISTINCT\n",
    "            codigo_ibge,\n",
    "            posexplode(payload.hourly.time) AS (idx, time),\n",
    "            payload.elevation,\n",
    "            payload.latitude,\n",
    "            payload.longitude,\n",
    "            payload.timezone,\n",
    "            payload.timezone_abbreviation,\n",
    "            payload.utc_offset_seconds\n",
    "        FROM clima_municipios\n",
    "    )\n",
    "    SELECT DISTINCT\n",
    "        _time.idx,\n",
    "        _time.codigo_ibge,\n",
    "        CAST(_time.time AS TIMESTAMP) AS time,\n",
    "        _time.elevation,\n",
    "        _time.latitude,\n",
    "        _time.longitude,\n",
    "        _time.timezone,\n",
    "        _time.timezone_abbreviation,\n",
    "        _time.utc_offset_seconds\n",
    "    FROM _time\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refined - HUMIDADE RELATIVA\n",
    "refined = spark.sql(\"\"\"\n",
    "    WITH _relativehumidity AS (\n",
    "        SELECT DISTINCT\n",
    "            codigo_ibge,\n",
    "            posexplode(payload.hourly.relativehumidity_2m) AS (idx, relativehumidity_2m), \n",
    "            payload.hourly_units.relativehumidity_2m AS unit_relativehumidity_2m\n",
    "        FROM clima_municipios\n",
    "    )\n",
    "    SELECT DISTINCT\n",
    "        _relativehumidity.idx,\n",
    "        _relativehumidity.codigo_ibge,\n",
    "        _relativehumidity.relativehumidity_2m,\n",
    "        _relativehumidity.unit_relativehumidity_2m\n",
    "    FROM _relativehumidity\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refined - TEMPERATURA\n",
    "refined = spark.sql(\"\"\"\n",
    "    WITH _temperature AS (\n",
    "        SELECT DISTINCT\n",
    "            codigo_ibge,\n",
    "            posexplode(payload.hourly.temperature_2m) AS (idx, temperature_2m),\n",
    "            payload.hourly_units.temperature_2m AS unit_temperature_2m\n",
    "        FROM clima_municipios\n",
    "    )\n",
    "    SELECT DISTINCT\n",
    "        _temperature.idx,\n",
    "        _temperature.codigo_ibge,\n",
    "        _temperature.temperature_2m,\n",
    "        _temperature.unit_temperature_2m\n",
    "    FROM _temperature\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refined - VELOCIDADE DO VENTO\n",
    "refined = spark.sql(\"\"\"\n",
    "    WITH _windspeed AS (\n",
    "        SELECT DISTINCT\n",
    "            codigo_ibge,\n",
    "            posexplode(payload.hourly.windspeed_10m) AS (idx, windspeed_10m),\n",
    "            payload.hourly_units.windspeed_10m AS unit_windspeed_10m\n",
    "        FROM clima_municipios\n",
    "    )\n",
    "    SELECT DISTINCT\n",
    "        _windspeed.idx,\n",
    "        _windspeed.codigo_ibge,\n",
    "        _windspeed.windspeed_10m,\n",
    "        _windspeed.unit_windspeed_10m\n",
    "    FROM _windspeed\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # refined - FULL QUERY\n",
    "# refined = spark.sql(\"\"\"\n",
    "#     WITH _time AS (\n",
    "#         SELECT DISTINCT\n",
    "#             codigo_ibge,\n",
    "#             posexplode(payload.hourly.time) AS (idx, time),\n",
    "#             payload.elevation,\n",
    "#             payload.latitude,\n",
    "#             payload.longitude,\n",
    "#             payload.timezone,\n",
    "#             payload.timezone_abbreviation,\n",
    "#             payload.utc_offset_seconds,                    \n",
    "#             payload.hourly AS hourly,                    \n",
    "#             payload.hourly_units AS hourly_units\n",
    "#         FROM clima_municipios\n",
    "#     ), _relativehumidity AS (\n",
    "#         SELECT DISTINCT\n",
    "#             codigo_ibge,\n",
    "#             time,\n",
    "#             posexplode(hourly.relativehumidity_2m) AS (idx, relativehumidity_2m), \n",
    "#             hourly_units.relativehumidity_2m AS unit_relativehumidity_2m\n",
    "#         FROM _time        \n",
    "#         WHERE CAST(time AS DATE) BETWEEN '2022-01-01' AND '2022-12-31'\n",
    "#     ), _temperature AS (\n",
    "#         SELECT DISTINCT\n",
    "#             codigo_ibge,\n",
    "#             time,\n",
    "#             posexplode(hourly.temperature_2m) AS (idx, temperature_2m),\n",
    "#             hourly_units.temperature_2m AS unit_temperature_2m\n",
    "#         FROM _time\n",
    "#         WHERE CAST(time AS DATE) BETWEEN '2022-01-01' AND '2022-12-31'\n",
    "#     ), _windspeed AS (\n",
    "#         SELECT DISTINCT\n",
    "#             codigo_ibge,\n",
    "#             time,\n",
    "#             posexplode(hourly.windspeed_10m) AS (idx, windspeed_10m),\n",
    "#             hourly_units.windspeed_10m AS unit_windspeed_10m\n",
    "#         FROM _time\n",
    "#         WHERE CAST(time AS DATE) BETWEEN '2022-01-01' AND '2022-12-31'\n",
    "#     )\n",
    "#     SELECT DISTINCT\n",
    "#         _time.codigo_ibge,\n",
    "#         CAST(_time.time AS TIMESTAMP) AS time,\n",
    "#         _relativehumidity.relativehumidity_2m,\n",
    "#         _relativehumidity.unit_relativehumidity_2m,\n",
    "#         _temperature.temperature_2m,\n",
    "#         _temperature.unit_temperature_2m,\n",
    "#         _windspeed.windspeed_10m,\n",
    "#         _windspeed.unit_windspeed_10m,\n",
    "#         _time.elevation,\n",
    "#         _time.latitude,\n",
    "#         _time.longitude,\n",
    "#         _time.timezone,\n",
    "#         _time.timezone_abbreviation,\n",
    "#         _time.utc_offset_seconds\n",
    "#     FROM _time\n",
    "#     INNER JOIN _relativehumidity ON _time.codigo_ibge = _relativehumidity.codigo_ibge AND _time.time = _relativehumidity.time AND _time.idx = _relativehumidity.idx\n",
    "#     INNER JOIN _temperature ON _time.codigo_ibge = _temperature.codigo_ibge AND _time.time = _temperature.time AND _time.idx = _temperature.idx\n",
    "#     INNER JOIN _windspeed ON _time.codigo_ibge = _windspeed.codigo_ibge AND _time.time = _windspeed.time AND _time.idx = _windspeed.idx\n",
    "#     ORDER BY time\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERT\n",
    "\n",
    "# refined.write.parquet(\"s3a://datalake/refined/clima_municipios_brasileiros/2000_2022/Centro-Oeste\", mode=\"overwrite\")\n",
    "# refined.write.parquet(\"s3a://datalake/refined/clima_municipios_brasileiros/2000_2022/Nordeste\")\n",
    "# refined.write.parquet(\"s3a://datalake/refined/clima_municipios_brasileiros/2000_2022/Norte\")\n",
    "# refined.write.parquet(\"s3a://datalake/refined/clima_municipios_brasileiros/2000_2022/Sudeste\")\n",
    "# refined.write.parquet(\"s3a://datalake/refined/clima_municipios_brasileiros/2000_2022/Sul\")\n",
    "\n",
    "# (\n",
    "#     refined.write\n",
    "#     .option(\"overwriteSchema\", \"true\")\n",
    "#     .format(\"delta\")\n",
    "#     .mode(\"overwrite\")\n",
    "#     .save(\"s3a://datalake/refined/clima_municipios_brasileiros\")\n",
    "#     # .save(\"s3a://datalake/refined/clima_municipios_brasileiros/tempo/2000_2022\")\n",
    "#     # .save(\"s3a://datalake/refined/clima_municipios_brasileiros/humidade/2000_2022\")\n",
    "#     # .save(\"s3a://datalake/refined/clima_municipios_brasileiros/temperatura/2000_2022\")\n",
    "#     # .save(\"s3a://datalake/refined/clima_municipios_brasileiros/velocidade_do_vento/2000_2022\")\n",
    "#     # .save(\"s3a://datalake/refined/clima_municipios_brasileiros/tempo\")\n",
    "#     # .save(\"s3a://datalake/refined/clima_municipios_brasileiros/humidade\")\n",
    "#     # .save(\"s3a://datalake/refined/clima_municipios_brasileiros/temperatura\")\n",
    "#     # .save(\"s3a://datalake/refined/clima_municipios_brasileiros/velocidade_do_vento\")\n",
    "# )\n",
    "\n",
    "(\n",
    "    refined.write\n",
    "    .format(\"parquet\")\n",
    "    .mode(\"overwrite\")\n",
    "    # .save(\"s3a://datalake/refined/clima_municipios_brasileiros/temporalidade/2000_2022\")\n",
    "    # .save(\"s3a://datalake/refined/clima_municipios_brasileiros/humidade/2000_2022\")\n",
    "    # .save(\"s3a://datalake/refined/clima_municipios_brasileiros/temperatura/2000_2022\")\n",
    "    .save(\"s3a://datalake/refined/clima_municipios_brasileiros/velocidade_do_vento/2000_2022\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPSERT\n",
    "\n",
    "from delta.tables import *\n",
    "\n",
    "refined_old = DeltaTable.forPath(spark, \"s3a://datalake/refined/clima_municipios_brasileiros/tempo\")\n",
    "\n",
    "(\n",
    "    refined_old.alias(\"old\")\n",
    "    .merge(\n",
    "        source=refined.alias(\"new\"), \n",
    "        condition=\"old.codigo_ibge = new.codigo_ibge AND old.time = new.time\"\n",
    "    )\n",
    "    .whenMatchedUpdateAll()\n",
    "    .whenNotMatchedInsertAll()\n",
    "    .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALVE TRUSTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.load(path=\"s3a://datalake/refined/clima_municipios_brasileiros/temporalidade/2000_2022\", format=\"parquet\") \\\n",
    "    .createOrReplaceTempView(\"clima_municipios_temporalidade\")\n",
    "spark.read.load(path=\"s3a://datalake/refined/clima_municipios_brasileiros/humidade/2000_2022\", format=\"parquet\") \\\n",
    "    .createOrReplaceTempView(\"clima_municipios_humidade\")\n",
    "spark.read.load(path=\"s3a://datalake/refined/clima_municipios_brasileiros/temperatura/2000_2022\", format=\"parquet\") \\\n",
    "    .createOrReplaceTempView(\"clima_municipios_temperatura\")\n",
    "spark.read.load(path=\"s3a://datalake/refined/clima_municipios_brasileiros/velocidade_do_vento/2000_2022\", format=\"parquet\") \\\n",
    "    .createOrReplaceTempView(\"clima_municipios_velocidade_do_vento\")\n",
    "\n",
    "trusted = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        tm.codigo_ibge,\n",
    "        CAST(tm.time AS TIMESTAMP) AS data_hora,\n",
    "        hm.relativehumidity_2m AS humidade_relativa,\n",
    "        hm.unit_relativehumidity_2m AS unidade_humidade_relativa,\n",
    "        tp.temperature_2m AS temperatura,\n",
    "        tp.unit_temperature_2m AS unidade_temperatura,\n",
    "        vv.windspeed_10m AS velocidade_do_vento,\n",
    "        vv.unit_windspeed_10m AS unidade_velocidade_do_vento,\n",
    "        tm.elevation AS elevacao,\n",
    "        tm.latitude,\n",
    "        tm.longitude,\n",
    "        tm.timezone AS fuso_horario,\n",
    "        tm.timezone_abbreviation AS abreviacao_fuso_horario,\n",
    "        tm.utc_offset_seconds AS deslocamento_fuso_horario_em_segundos,\n",
    "        current_timestamp() AS gerado_em\n",
    "    FROM clima_municipios_tempo tm\n",
    "    INNER JOIN clima_municipios_humidade hm ON hm.codigo_ibge = tm.codigo_ibge AND hm.idx = tm.idx\n",
    "    INNER JOIN clima_municipios_temperatura tp ON tp.codigo_ibge = tm.codigo_ibge AND tp.idx = tm.idx\n",
    "    INNER JOIN clima_municipios_velocidade_do_vento vv ON vv.codigo_ibge = tm.codigo_ibge AND vv.idx = tm.idx\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trusted = (\n",
    "    trusted\n",
    "    .withMetadata(\"codigo_ibge\", { \"tipo\": \"NUMERICO\", \"descricao\": \"Código composto de 7 dígitos, sendo os dois primeiros referentes ao código da Unidade da Federação\" })\n",
    "    .withMetadata(\"data_hora\", { \"tipo\": \"DATA E HORA\", \"descricao\": \"Data e hora dos dados meteorológicos\" })\n",
    "    .withMetadata(\"humidade_relativa\", { \"tipo\": \"NUMERICO\", \"descricao\": \"Umidade relativa a 2 metros acima do solo\" })\n",
    "    .withMetadata(\"unidade_humidade_relativa\", { \"tipo\": \"TEXTO\", \"descricao\": \"Unidade de medida da umidade relativa\" })\n",
    "    .withMetadata(\"temperatura\", { \"tipo\": \"NUMERICO\", \"descricao\": \"Temperatura do ar a 2 metros acima do solo\" })\n",
    "    .withMetadata(\"unidade_temperatura\", { \"tipo\": \"TEXTO\", \"descricao\": \"Unidade de medida da temperatura do ar\" })\n",
    "    .withMetadata(\"velocidade_do_vento\", { \"tipo\": \"NUMERICO\", \"descricao\": \"Velocidade do vento a 10 metros acima do solo\" })\n",
    "    .withMetadata(\"unidade_velocidade_do_vento\", { \"tipo\": \"TEXTO\", \"descricao\": \"Unidade de medida da velocidade do vento\" })\n",
    "    .withMetadata(\"elevacao\", { \"tipo\": \"NUMERICO\", \"descricao\": \"A elevação usada para redução de escala estatística. Por padrão, um modelo de elevação digital de 90 metros é usado\" })\n",
    "    .withMetadata(\"latitude\", { \"tipo\": \"NUMERICO\", \"descricao\": \"Latitude do município\" })\n",
    "    .withMetadata(\"longitude\", { \"tipo\": \"NUMERICO\", \"descricao\": \"Longitude do município\" })\n",
    "    .withMetadata(\"fuso_horario\", { \"tipo\": \"TEXTO\", \"descricao\": \"Fuso horário considerado para o campo time\" })\n",
    "    .withMetadata(\"abreviacao_fuso_horario\", { \"tipo\": \"TEXTO\", \"descricao\": \"Abreviação do fuso horário\" })\n",
    "    .withMetadata(\"deslocamento_fuso_horario_em_segundos\", { \"tipo\": \"NUMERICO\", \"descricao\": \"Deslocamento do fuso horário em segundos\" })\n",
    "    .withMetadata(\"gerado_em\", { \"tipo\": \"DATA E HORA\", \"descricao\": \"Identifica a data e hora que o registro foi gerado pela orquestração\" })\n",
    ")\n",
    "\n",
    "# (\n",
    "#     trusted.write\n",
    "#     .option(\"overwriteSchema\", \"true\")\n",
    "#     .format(\"delta\")\n",
    "#     .mode(\"overwrite\")\n",
    "#     .save(\"s3a://datalake/trusted/clima_municipios_brasileiros\")\n",
    "# )\n",
    "\n",
    "(\n",
    "    trusted.write\n",
    "    .format(\"parquet\")\n",
    "    .mode(\"overwrite\")    \n",
    "    .partitionBy(\"codigo_ibge\", \"data_hora\")\n",
    "    .save(\"s3a://datalake/trusted/clima_municipios_brasileiros\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af95bfb7fb293ddecfb703018a12b28bc1ac3690b724bc75ec9b6f8e0f0389c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
